{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BD6rjLjXiWjL",
        "hUxiaQbjm4yn"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Intro to Apache Spark"
      ],
      "metadata": {
        "id": "BD6rjLjXiWjL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Start a Spark Session\n",
        "\n",
        "`pyspark.sql` is a PySpark module that provides tools for working with structured data using DataFrames and SQL-like queries."
      ],
      "metadata": {
        "id": "1oBjWcGdgXSs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6_1BRl5fa-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d76be3b0-bb3c-49da-d8da-fbc2bccb2187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+---+----------+-----------+\n",
            "|Name|Sex|Age|Height(in)|Weight(lbs)|\n",
            "+----+---+---+----------+-----------+\n",
            "|Alex|  M| 41|        74|        170|\n",
            "|Bert|  M| 42|        68|        166|\n",
            "|Dave|  M| 32|        70|        155|\n",
            "|Dave|  M| 39|        72|        167|\n",
            "|Elly|  F| 30|        66|        124|\n",
            "+----+---+---+----------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Start Spark\n",
        "spark = SparkSession.builder.appName(\"Biostats Analysis\").getOrCreate()\n",
        "\n",
        "# Load CSV file\n",
        "df = spark.read.csv(\"Biostats.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# View first rows\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Explore schema"
      ],
      "metadata": {
        "id": "2ClX8Q7bhJTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5m8-Gc_hKTS",
        "outputId": "50038da1-594d-4a9a-fbba-5a27df36f186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Height(in): integer (nullable = true)\n",
            " |-- Weight(lbs): integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Select Columns"
      ],
      "metadata": {
        "id": "I2uv7YUQhM_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"Name\", \"Age\", \"Sex\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O160F1xJhQFd",
        "outputId": "4777dcaf-b598-40e6-e3b0-67ab121537b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+---+\n",
            "|Name|Age|Sex|\n",
            "+----+---+---+\n",
            "|Alex| 41|  M|\n",
            "|Bert| 42|  M|\n",
            "|Dave| 32|  M|\n",
            "|Dave| 39|  M|\n",
            "|Elly| 30|  F|\n",
            "|Fran| 33|  F|\n",
            "|Gwen| 26|  F|\n",
            "|Hank| 30|  M|\n",
            "|Luke| 53|  M|\n",
            "|Jake| 32|  M|\n",
            "|Kate| 47|  F|\n",
            "|Luke| 34|  M|\n",
            "|Myra| 23|  F|\n",
            "|Neil| 36|  M|\n",
            "|Omar| 38|  M|\n",
            "|Page| 31|  F|\n",
            "|Luke| 29|  M|\n",
            "|Ruth| 28|  F|\n",
            "+----+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Filter: People older than 40"
      ],
      "metadata": {
        "id": "eZELMDr1hR4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(df[\"Age\"] > 40).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq0y-lHChT1y",
        "outputId": "e7d60e51-50ed-4deb-ec85-d13a12322cde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+---+----------+-----------+\n",
            "|Name|Sex|Age|Height(in)|Weight(lbs)|\n",
            "+----+---+---+----------+-----------+\n",
            "|Alex|  M| 41|        74|        170|\n",
            "|Bert|  M| 42|        68|        166|\n",
            "|Luke|  M| 53|        72|        175|\n",
            "|Kate|  F| 47|        69|        139|\n",
            "+----+---+---+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Sort by Weight descending order."
      ],
      "metadata": {
        "id": "kEgv0m5NhWxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.orderBy(df[\"Weight(lbs)\"].desc()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rxgc9FlIhXUJ",
        "outputId": "928cf633-aeff-4367-bd87-2c0a3a9604b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+---+----------+-----------+\n",
            "|Name|Sex|Age|Height(in)|Weight(lbs)|\n",
            "+----+---+---+----------+-----------+\n",
            "|Luke|  M| 29|        71|        176|\n",
            "|Luke|  M| 53|        72|        175|\n",
            "|Alex|  M| 41|        74|        170|\n",
            "|Dave|  M| 39|        72|        167|\n",
            "|Bert|  M| 42|        68|        166|\n",
            "|Luke|  M| 34|        72|        163|\n",
            "|Neil|  M| 36|        75|        160|\n",
            "|Hank|  M| 30|        71|        158|\n",
            "|Dave|  M| 32|        70|        155|\n",
            "|Omar|  M| 38|        70|        145|\n",
            "|Jake|  M| 32|        69|        143|\n",
            "|Kate|  F| 47|        69|        139|\n",
            "|Page|  F| 31|        67|        135|\n",
            "|Ruth|  F| 28|        65|        131|\n",
            "|Elly|  F| 30|        66|        124|\n",
            "|Gwen|  F| 26|        64|        121|\n",
            "|Fran|  F| 33|        66|        115|\n",
            "|Myra|  F| 23|        62|         98|\n",
            "+----+---+---+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Group by Sex and Count"
      ],
      "metadata": {
        "id": "50aLbsdxhazP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"Sex\").count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWHBcF5bha9v",
        "outputId": "97681562-a627-47ef-9a05-b37bba5223f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+\n",
            "|Sex|count|\n",
            "+---+-----+\n",
            "|  F|    7|\n",
            "|  M|   11|\n",
            "+---+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Average Weight by Sex\n"
      ],
      "metadata": {
        "id": "i3Bi-6mXhqVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"Sex\").avg(\"Weight(lbs)\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FSvIO6ehqoz",
        "outputId": "775a951b-d96c-4c8c-93bb-d8042bc1d454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------------+\n",
            "|Sex|  avg(Weight(lbs))|\n",
            "+---+------------------+\n",
            "|  F|123.28571428571429|\n",
            "|  M|161.63636363636363|\n",
            "+---+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Before running SQL queries, register the DataFrame as a temporary view. Now you can query it like a regular SQL table.\n"
      ],
      "metadata": {
        "id": "lxiFHhRmh5LN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"biostats\")"
      ],
      "metadata": {
        "id": "N2jE4BgNh5Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.  Select Name, Age, Sex"
      ],
      "metadata": {
        "id": "6PfkYsuUh_ji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT Name, Age, Sex FROM biostats\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LTPYfvbiF5D",
        "outputId": "8da42493-acbf-45b5-fca9-51ca68c96ad3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+---+\n",
            "|Name|Age|Sex|\n",
            "+----+---+---+\n",
            "|Alex| 41|  M|\n",
            "|Bert| 42|  M|\n",
            "|Dave| 32|  M|\n",
            "|Dave| 39|  M|\n",
            "|Elly| 30|  F|\n",
            "|Fran| 33|  F|\n",
            "|Gwen| 26|  F|\n",
            "|Hank| 30|  M|\n",
            "|Luke| 53|  M|\n",
            "|Jake| 32|  M|\n",
            "|Kate| 47|  F|\n",
            "|Luke| 34|  M|\n",
            "|Myra| 23|  F|\n",
            "|Neil| 36|  M|\n",
            "|Omar| 38|  M|\n",
            "|Page| 31|  F|\n",
            "|Luke| 29|  M|\n",
            "|Ruth| 28|  F|\n",
            "+----+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Filter: People older than 40"
      ],
      "metadata": {
        "id": "Y6CB4djUiKlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT * FROM biostats WHERE Age > 40\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PImout5iO4s",
        "outputId": "08fbb5fc-fe12-40ce-b886-8ec06596cc89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+---+----------+-----------+\n",
            "|Name|Sex|Age|Height(in)|Weight(lbs)|\n",
            "+----+---+---+----------+-----------+\n",
            "|Alex|  M| 41|        74|        170|\n",
            "|Bert|  M| 42|        68|        166|\n",
            "|Luke|  M| 53|        72|        175|\n",
            "|Kate|  F| 47|        69|        139|\n",
            "+----+---+---+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Data cleaning with Spark"
      ],
      "metadata": {
        "id": "itemLKCkia_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Load the CSV"
      ],
      "metadata": {
        "id": "1EWxpgYOkbmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"DataFrameMapReduce\").getOrCreate()\n",
        "df = spark.read.csv(\"Movies.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "UlupcSElid-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Clean the data"
      ],
      "metadata": {
        "id": "Tw3iN686lYFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lower, trim\n",
        "\n",
        "df = df.withColumn(\"Genre_clean\", trim(lower(df[\"Genre\"])))\n",
        "\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "df = df.withColumn(\n",
        "    \"Genre_fixed\",\n",
        "    when(df[\"Genre_clean\"] == \"comdy\", \"comedy\")\n",
        "    .when(df[\"Genre_clean\"] == \"romence\", \"romance\")\n",
        "    .when(df[\"Genre_clean\"] == \"romance\", \"romance\")\n",
        "    .when(df[\"Genre_clean\"] == \"comedy\", \"comedy\")\n",
        "    .when(df[\"Genre_clean\"] == \"action\", \"action\")\n",
        "    .when(df[\"Genre_clean\"] == \"drama\", \"drama\")\n",
        "    .when(df[\"Genre_clean\"] == \"animation\", \"animation\")\n",
        "    .when(df[\"Genre_clean\"] == \"fantasy\", \"fantasy\")\n",
        "    .otherwise(df[\"Genre_clean\"])\n",
        ")"
      ],
      "metadata": {
        "id": "1pkggZkBlJQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Run the map reduce process"
      ],
      "metadata": {
        "id": "R4Mz8xKNi4GE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"Genre_clean\").count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHEhRPQkkkm1",
        "outputId": "cc26ab67-57e1-42cc-80de-46ec4d393934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+\n",
            "|Genre_clean|count|\n",
            "+-----------+-----+\n",
            "|    fantasy|    1|\n",
            "|     action|    1|\n",
            "|  animation|    4|\n",
            "|      comdy|    1|\n",
            "|    romence|    1|\n",
            "|      drama|   13|\n",
            "|    romance|   13|\n",
            "|     comedy|   42|\n",
            "+-----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Group in ascending order"
      ],
      "metadata": {
        "id": "MAr0DTBvldrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"Genre_fixed\").count().orderBy(\"count\", ascending=False).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfip50_clfVQ",
        "outputId": "d7ac2488-dd8f-424a-df3f-166d37d77d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+\n",
            "|Genre_fixed|count|\n",
            "+-----------+-----+\n",
            "|     comedy|   43|\n",
            "|    romance|   14|\n",
            "|      drama|   13|\n",
            "|  animation|    4|\n",
            "|    fantasy|    1|\n",
            "|     action|    1|\n",
            "+-----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Save as CSV"
      ],
      "metadata": {
        "id": "GuHFMlEillFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genre_counts = df.groupBy(\"Genre_fixed\").count().orderBy(\"count\", ascending=False)\n",
        "genre_counts.write.csv(\"output\", header=True, mode=\"overwrite\")"
      ],
      "metadata": {
        "id": "p1i2hUL_lmrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Load the movies file"
      ],
      "metadata": {
        "id": "Bc8daz-EpqRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"MoviesCleaning\").getOrCreate()\n",
        "df = spark.read.csv(\"Movies.csv\", header=True, inferSchema=True)\n",
        "df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q0BSUwApsDi",
        "outputId": "e75f8c56-9003-4a8b-c010-62e7ab7a8a64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Film: string (nullable = true)\n",
            " |-- Genre: string (nullable = true)\n",
            " |-- Lead Studio: string (nullable = true)\n",
            " |-- Audience score %: integer (nullable = true)\n",
            " |-- Profitability: double (nullable = true)\n",
            " |-- Rotten Tomatoes %: integer (nullable = true)\n",
            " |-- Worldwide Gross: string (nullable = true)\n",
            " |-- Year: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Drop rows with missing key fields"
      ],
      "metadata": {
        "id": "E7v396mVpt-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(subset=[\"Film\", \"Genre\", \"Audience score %\", \"Profitability\"])"
      ],
      "metadata": {
        "id": "9XrHdkDJpwc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Clean and standardize names"
      ],
      "metadata": {
        "id": "pJhifcIsp14q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import trim, lower, when, col\n",
        "\n",
        "# Create cleaned genre\n",
        "df = df.withColumn(\"Genre_clean\", trim(lower(col(\"Genre\"))))\n",
        "\n",
        "# Fix typos\n",
        "df = df.withColumn(\"Genre_fixed\",\n",
        "    when(col(\"Genre_clean\") == \"comdy\", \"comedy\")\n",
        "    .when(col(\"Genre_clean\") == \"romence\", \"romance\")\n",
        "    .otherwise(col(\"Genre_clean\"))\n",
        ")"
      ],
      "metadata": {
        "id": "hNHRcD04p4rO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Clean and convert Worldwide Gross to numeric"
      ],
      "metadata": {
        "id": "hXn-WWc6p65E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import regexp_replace\n",
        "\n",
        "df = df.withColumn(\"Worldwide_Gross_Clean\",\n",
        "    regexp_replace(\"Worldwide Gross\", \"[$,]\", \"\").cast(\"float\")\n",
        ")"
      ],
      "metadata": {
        "id": "3P5bvkTIp7qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Convert to data types"
      ],
      "metadata": {
        "id": "0zjqftlUp__1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn(\"Profitability\", col(\"Profitability\").cast(\"float\"))\n",
        "df = df.withColumn(\"Audience_Score\", col(\"Audience score %\").cast(\"float\"))"
      ],
      "metadata": {
        "id": "fdmrHvjBqA3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Drop duplicated"
      ],
      "metadata": {
        "id": "BXxtT_b9qE7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropDuplicates([\"Film\", \"Year\"])"
      ],
      "metadata": {
        "id": "INFWL0d8qHGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Check final schema"
      ],
      "metadata": {
        "id": "fmOjHyXrqJdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()\n",
        "df.select(\"Film\", \"Genre_fixed\", \"Audience_Score\", \"Profitability\", \"Worldwide_Gross_Clean\").show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gx_QO_hZqLpA",
        "outputId": "0ec98e4a-5150-4c75-a892-b798a4c8b72b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Film: string (nullable = true)\n",
            " |-- Genre: string (nullable = true)\n",
            " |-- Lead Studio: string (nullable = true)\n",
            " |-- Audience score %: integer (nullable = true)\n",
            " |-- Profitability: float (nullable = true)\n",
            " |-- Rotten Tomatoes %: integer (nullable = true)\n",
            " |-- Worldwide Gross: string (nullable = true)\n",
            " |-- Year: integer (nullable = true)\n",
            " |-- Genre_clean: string (nullable = true)\n",
            " |-- Genre_fixed: string (nullable = true)\n",
            " |-- Worldwide_Gross_Clean: float (nullable = true)\n",
            " |-- Audience_Score: float (nullable = true)\n",
            "\n",
            "+--------------------+-----------+--------------+-------------+---------------------+\n",
            "|                Film|Genre_fixed|Audience_Score|Profitability|Worldwide_Gross_Clean|\n",
            "+--------------------+-----------+--------------+-------------+---------------------+\n",
            "|(500) Days of Summer|     comedy|          81.0|        8.096|                60.72|\n",
            "|          27 Dresses|     comedy|          71.0|    5.3436217|               160.31|\n",
            "|  A Dangerous Method|      drama|          89.0|   0.44864476|                 8.97|\n",
            "|       A Serious Man|      drama|          64.0|    4.3828573|                30.68|\n",
            "|           Beginners|     comedy|          80.0|     4.471875|                14.31|\n",
            "+--------------------+-----------+--------------+-------------+---------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Save to a new directory with a single CSV file\n"
      ],
      "metadata": {
        "id": "FaH9YPEEqZAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.coalesce(1).write.csv(\"cleaned_movies_output\", header=True, mode=\"overwrite\")"
      ],
      "metadata": {
        "id": "VNmlsY7_qZMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Exercises"
      ],
      "metadata": {
        "id": "DcsNNaumqtlw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Show the first 5 records\n",
        "\n",
        "* Question: Display the first five rows of the dataset.\n",
        "\n",
        "üí° Hint: Use .show(5) after reading the CSV with spark.read.csv().\n",
        "\n",
        "2. Display the schema of the dataset\n",
        "\n",
        "* Question: What are the data types of each column?\n",
        "\n",
        "üí° Hint: Use .printSchema() to inspect structure and types.\n",
        "\n",
        "3. Count how many startups are from each country\n",
        "\n",
        "* Question: Find the number of unicorns per country.\n",
        "\n",
        "üí° Hint: Use groupBy(\"Country\").count() and sort with .orderBy(...).\n",
        "\n",
        "4. What are the top 10 most valuable startups?\n",
        "\n",
        "* Question: List the 10 companies with the highest valuation.\n",
        "\n",
        "üí° Hint: Make sure Valuation is numeric ‚Üí use .cast(\"float\"), then .orderBy(...).\n",
        "\n",
        "5. Filter all startups in the Fintech industry\n",
        "\n",
        "* Question: Find all rows where the industry is ‚ÄúFintech‚Äù.\n",
        "\n",
        "üí° Hint: Use .filter(col(\"Industry\") == \"Fintech\").\n",
        "\n",
        "6. Count how many unicorns each city has\n",
        "\n",
        "* Question: Group by City and count the number of entries.\n",
        "\n",
        "üí° Hint: groupBy(\"City\").count() ‚Äî sort to see top cities.\n",
        "\n",
        "7. Count how many unicorns were founded each year\n",
        "\n",
        "* Question: Count unicorns per year from the Date column.\n",
        "\n",
        "üí° Hint:\n",
        "\n",
        "Use to_date(\"Date\", \"M/d/yyyy\")\n",
        "\n",
        "Extract year() to a new column\n",
        "\n",
        "Group and count by Year\n",
        "\n",
        "8. What‚Äôs the average valuation per industry?\n",
        "\n",
        "* Question: Calculate and rank average startup valuation by industry.\n",
        "\n",
        "üí° Hint:\n",
        "\n",
        "Cast Valuation to float\n",
        "\n",
        "Use groupBy(\"Industry\").avg(...)\n",
        "\n",
        "Order by the result\n",
        "\n",
        "9. Create a new column to flag U.S. startups\n",
        "\n",
        "* Question: Add a column Is_USA to mark startups from the U.S.\n",
        "\n",
        "üí° Hint: Use withColumn(\"Is_USA\", col(\"Country\") == \"United States\")\n",
        "\n",
        "10. Save the cleaned DataFrame to a CSV file\n",
        "* Question: Write the cleaned and transformed DataFrame to disk.\n",
        "\n",
        "üí° Hint: Use coalesce(1).write.csv(..., header=True, mode=\"overwrite\")"
      ],
      "metadata": {
        "id": "TiNpcFWqqv1B"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q2TpbG30rBKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Exercises solutions"
      ],
      "metadata": {
        "id": "hUxiaQbjm4yn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the following data: https://www.kaggle.com/datasets/uzairrehman/world-wide-unicorn-startups"
      ],
      "metadata": {
        "id": "j9DMaTgzm6bZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Load the dataset"
      ],
      "metadata": {
        "id": "D6pWb2RhnCWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Unicorns\").getOrCreate()\n",
        "\n",
        "df = spark.read.csv(\"World_Wide_Unicorn_Startups.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "bVQoAlbqm8ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Show the first 5 records\n"
      ],
      "metadata": {
        "id": "YPB3kxpbnLyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DIcv5AQnPr9",
        "outputId": "dd0e70e6-9ff4-4f8b-c329-971775a9245e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+----------+-------+-------+--------------------+--------------------+----+-----+----+\n",
            "|             Company|           Valuation|      Date|Country|   City|            Industry|           Investors|year|month| day|\n",
            "+--------------------+--------------------+----------+-------+-------+--------------------+--------------------+----+-----+----+\n",
            "|           Bytedance|               140.0|  4/7/2017|  China|Beijing|Artificial intell...|0      Sequoia Ca...|NULL| NULL|NULL|\n",
            "|1      Founders Fund| Draper Fisher Ju...| Rothen...|   NULL|   NULL|                NULL|                NULL|NULL| NULL|NULL|\n",
            "|2            Khos...|    LowercaseCapital|  capitalG|   NULL|   NULL|                NULL|                NULL|NULL| NULL|NULL|\n",
            "|3      Institutio...|   Sequoia Capita...|      NULL|   NULL|   NULL|                NULL|                NULL|NULL| NULL|NULL|\n",
            "|4      Sequoia Ca...|  Blackbird Ventures|    Mat...|   NULL|   NULL|                NULL|                NULL|NULL| NULL|NULL|\n",
            "+--------------------+--------------------+----------+-------+-------+--------------------+--------------------+----+-----+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Show the schema of the DataFrame"
      ],
      "metadata": {
        "id": "xebDanFsnRJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQSr51l2nTw4",
        "outputId": "1f39bb85-1683-4e68-f66c-4f9483b06d0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Company: string (nullable = true)\n",
            " |-- Valuation: string (nullable = true)\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- Industry: string (nullable = true)\n",
            " |-- Investors: string (nullable = true)\n",
            " |-- year: string (nullable = true)\n",
            " |-- month: string (nullable = true)\n",
            " |-- day: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Count how many startups are from each country"
      ],
      "metadata": {
        "id": "SpHRXxDunWIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"Country\").count().orderBy(\"count\", ascending=False).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7Qgs2MLnSmO",
        "outputId": "f19807ad-166c-4059-b661-139f7169c08e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+------+\n",
            "|           Country| count|\n",
            "+------------------+------+\n",
            "|              NULL|870480|\n",
            "|       Alibaba ...|   936|\n",
            "|             Go...|   936|\n",
            "| McKesson Ventures|   936|\n",
            "|               ...|   936|\n",
            "|              2021|   480|\n",
            "|     United States|   477|\n",
            "|             China|   169|\n",
            "|              2020|   110|\n",
            "|              2019|   110|\n",
            "|              2018|   107|\n",
            "|             India|    51|\n",
            "|              2017|    46|\n",
            "|              2015|    37|\n",
            "|    United Kingdom|    37|\n",
            "|           Germany|    23|\n",
            "|              2016|    22|\n",
            "|            Israel|    21|\n",
            "|            France|    19|\n",
            "|            Brazil|    15|\n",
            "+------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Find the top 10 most valuable startups"
      ],
      "metadata": {
        "id": "MxbBIRK8nbIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.orderBy(df[\"Valuation\"].desc()).select(\"Company\", \"Valuation\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIr2LNADnb6u",
        "outputId": "95bfaeed-747f-457a-c714-ace84b963eaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+\n",
            "|             Company|           Valuation|\n",
            "+--------------------+--------------------+\n",
            "|857    Hyde Park ...|\\tFundersClub. Ba...|\n",
            "|857    Hyde Park ...|\\tFundersClub. Ba...|\n",
            "|857    Hyde Park ...|\\tFundersClub. Ba...|\n",
            "|857    Hyde Park ...|\\tFundersClub. Ba...|\n",
            "|857    Hyde Park ...|\\tFundersClub. Ba...|\n",
            "|857    Hyde Park ...|\\tFundersClub. Ba...|\n",
            "|857    Hyde Park ...|\\tFundersClub. Ba...|\n",
            "|857    Hyde Park ...|\\tFundersClub. Ba...|\n",
            "|857    Hyde Park ...|\\tFundersClub. Ba...|\n",
            "|857    Hyde Park ...|\\tFundersClub. Ba...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Filter all startups in the Fintech industry"
      ],
      "metadata": {
        "id": "Z6ilFbvinfu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(df[\"Industry\"] == \"Fintech\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ja0mBcztngae",
        "outputId": "9e907828-0006-495d-f66b-36734ab86807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+----------+--------------+-------------+--------+--------------------+----+-----+----+\n",
            "|             Company|Valuation|      Date|       Country|         City|Industry|           Investors|year|month| day|\n",
            "+--------------------+---------+----------+--------------+-------------+--------+--------------------+----+-----+----+\n",
            "|              Stripe|     95.0| 1/23/2014| United States|San Francisco| Fintech|0      Sequoia Ca...|NULL| NULL|NULL|\n",
            "|              Klarna|     45.6|12/12/2011|        Sweden|    Stockholm| Fintech|0      Sequoia Ca...|NULL| NULL|NULL|\n",
            "|             Revolut|     33.0| 4/26/2018|United Kingdom|       London| Fintech|0      Sequoia Ca...|NULL| NULL|NULL|\n",
            "|              Nubank|     30.0|  3/1/2018|        Brazil|    Sao Paulo| Fintech|0      Sequoia Ca...|NULL| NULL|NULL|\n",
            "|               Chime|     25.0|  3/5/2019| United States|San Francisco| Fintech|0      Sequoia Ca...|NULL| NULL|NULL|\n",
            "|                 FTX|     25.0| 7/20/2021|     Hong Kong|         NULL| Fintech|0      Sequoia Ca...|NULL| NULL|NULL|\n",
            "|        Checkout.com|     15.0|  5/2/2019|United Kingdom|       London| Fintech|0      Sequoia Ca...|NULL| NULL|NULL|\n",
            "|  Plaid Technologies|     13.4|12/11/2018| United States|San Francisco| Fintech|0      Sequoia Ca...|NULL| NULL|NULL|\n",
            "|                Brex|     12.3| 10/5/2018| United States|San Francisco| Fintech|0      Sequoia Ca...|NULL| NULL|NULL|\n",
            "|              Ripple|     10.0|12/20/2019| United States|San Francisco| Fintech|0      Sequoia Ca...|NULL| NULL|NULL|\n",
            "|               Gusto|     10.0|12/18/2015| United States|San Francisco| Fintech|0      Sequoia Ca...|NULL| NULL|NULL|\n",
            "|                 N26|     9.23| 1/10/2019|       Germany|       Berlin| Fintech|0      Sequoia Ca...|NULL| NULL|NULL|\n",
            "|               Rapyd|     8.75| 12/3/2019|United Kingdom|       London| Fintech|0      Sequoia Ca...|NULL| NULL|NULL|\n",
            "|             Tipalti|      8.3| 10/6/2020| United States|    San Mateo| Fintech|0      Sequoia Ca...|NULL| NULL|NULL|\n",
            "|          Fireblocks|      8.0| 7/27/2021| United States|     New York| Fintech|0      Sequoia Ca...|NULL| NULL|NULL|\n",
            "|         Dapper Labs|      7.6| 3/30/2021|        Canada|    Vancouver| Fintech|0      Sequoia Ca...|NULL| NULL|NULL|\n",
            "|                Toss|      7.4| 12/9/2018|   South Korea|        Seoul| Fintech|0      Sequoia Ca...|NULL| NULL|NULL|\n",
            "|               Carta|      7.4|  5/6/2019| United States|San Francisco| Fintech|0      Sequoia Ca...|NULL| NULL|NULL|\n",
            "|              Gemini|      7.1|11/19/2021| United States|     New York| Fintech|0      Sequoia Ca...|NULL| NULL|NULL|\n",
            "|National Stock Ex...|      6.5|  7/1/2020|         India|       Mumbai| Fintech|0      Sequoia Ca...|NULL| NULL|NULL|\n",
            "+--------------------+---------+----------+--------------+-------------+--------+--------------------+----+-----+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Count how many unicorns each city has"
      ],
      "metadata": {
        "id": "vlhBgjiDniw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "s = time.time()\n",
        "\n",
        "df.groupBy(\"City\").count().orderBy(\"count\", ascending=False)\n",
        "\n",
        "print(time.time()-s)\n",
        "\n",
        "s = time.time()\n",
        "\n",
        "df.groupBy(\"City\").count().orderBy(\"count\", ascending=False).show(10)\n",
        "\n",
        "print(time.time()-s)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNUiZhtlnltf",
        "outputId": "23616e72-03e5-4a19-cf97-afb78f157870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.020714282989501953\n",
            "+-------------+------+\n",
            "|         City| count|\n",
            "+-------------+------+\n",
            "|         NULL|874239|\n",
            "|San Francisco|   134|\n",
            "|     New York|    81|\n",
            "|      Beijing|    62|\n",
            "|           16|    46|\n",
            "|     Shanghai|    45|\n",
            "|            1|    43|\n",
            "|           22|    40|\n",
            "|           21|    40|\n",
            "|           13|    39|\n",
            "+-------------+------+\n",
            "only showing top 10 rows\n",
            "\n",
            "2.237185001373291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Count unicorns per year"
      ],
      "metadata": {
        "id": "M9nictx6nmsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import to_date\n",
        "\n",
        "df = df.withColumn(\"ParsedDate\", to_date(\"Date\", \"M/d/yyyy\"))\n",
        "\n",
        "from pyspark.sql.functions import year\n",
        "\n",
        "df = df.withColumn(\"Year\", year(\"ParsedDate\"))\n",
        "\n",
        "df.groupBy(\"Year\").count().orderBy(\"Year\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMy2nFQ2nobA",
        "outputId": "5d354cbf-ee87-42f8-a05e-ac96925cd596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+\n",
            "|Year| count|\n",
            "+----+------+\n",
            "|NULL|875160|\n",
            "|2007|     1|\n",
            "|2010|     1|\n",
            "|2011|     2|\n",
            "|2012|     4|\n",
            "|2013|     3|\n",
            "|2014|    13|\n",
            "|2015|    37|\n",
            "|2016|    22|\n",
            "|2017|    46|\n",
            "|2018|   107|\n",
            "|2019|   110|\n",
            "|2020|   110|\n",
            "|2021|   480|\n",
            "+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Average valuation per industry"
      ],
      "metadata": {
        "id": "y2XuRnu9nrMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn(\"Valuation_numeric\", col(\"Valuation\").cast(\"float\"))\n",
        "\n",
        "df.groupBy(\"Industry\") \\\n",
        "  .avg(\"Valuation_numeric\") \\\n",
        "  .orderBy(\"avg(Valuation_numeric)\", ascending=False) \\\n",
        "  .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nezgZkwunspb",
        "outputId": "6977ab15-fbd7-4e17-9232-82ceb3f9cd63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------------------+\n",
            "|            Industry|avg(Valuation_numeric)|\n",
            "+--------------------+----------------------+\n",
            "|            Finttech|                  10.0|\n",
            "|               Other|     4.812941237991931|\n",
            "|Artificial intell...|     4.465797102969626|\n",
            "|             Fintech|    3.8638421033558092|\n",
            "|Data management &...|     3.380555556880103|\n",
            "|              Edtech|     3.161851860858776|\n",
            "|            Hardware|     3.080937512218952|\n",
            "|Auto & transporta...|     3.079310339072655|\n",
            "|Internet software...|     2.896766457728997|\n",
            "|Supply chain, log...|     2.868431374138477|\n",
            "|E-commerce & dire...|    2.8539215711986317|\n",
            "|   Consumer & retail|      2.78826089527296|\n",
            "|              Travel|    2.7384615678053637|\n",
            "|              Health|    2.6390476207884532|\n",
            "|       Cybersecurity|     2.622926857413315|\n",
            "|Mobile & telecomm...|    2.1375675555822014|\n",
            "|Artificial Intell...|     1.175000011920929|\n",
            "|                   7|                  NULL|\n",
            "|                  11|                  NULL|\n",
            "|                   3|                  NULL|\n",
            "+--------------------+----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.  Create a new column Is_USA to check if company is from United States"
      ],
      "metadata": {
        "id": "61cuGTAIo6xj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "df = df.withColumn(\"Is_USA\", col(\"Country\") == \"United States\")\n",
        "df.select(\"Company\", \"Country\", \"Is_USA\").show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAo6fCwUo72A",
        "outputId": "a2affa08-c499-4392-ee82-4189b8062647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------+------+\n",
            "|             Company|Country|Is_USA|\n",
            "+--------------------+-------+------+\n",
            "|           Bytedance|  China| false|\n",
            "|1      Founders Fund|   NULL|  NULL|\n",
            "|2            Khos...|   NULL|  NULL|\n",
            "|3      Institutio...|   NULL|  NULL|\n",
            "|4      Sequoia Ca...|   NULL|  NULL|\n",
            "+--------------------+-------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Save the cleaned and enriched dataset to CSV"
      ],
      "metadata": {
        "id": "pOkoytmzo_Is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.coalesce(1).write.csv(\"unicorns_cleaned.csv\", header=True, mode=\"overwrite\")"
      ],
      "metadata": {
        "id": "--aCOHiopAO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Solutions in Spark SQL"
      ],
      "metadata": {
        "id": "Y64DKb0RrTev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Setup"
      ],
      "metadata": {
        "id": "YOErcxZ5raoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import to_date, year, col\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Unicorns\").getOrCreate()\n",
        "\n",
        "# Load and prepare\n",
        "df = spark.read.csv(\"World_Wide_Unicorn_Startups.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Parse date and cast valuation\n",
        "df = df.withColumn(\"ParsedDate\", to_date(\"Date\", \"M/d/yyyy\"))\n",
        "df = df.withColumn(\"Year\", year(\"ParsedDate\"))\n",
        "df = df.withColumn(\"Valuation_numeric\", col(\"Valuation\").cast(\"float\"))\n",
        "\n",
        "# Register SQL view\n",
        "df.createOrReplaceTempView(\"unicorns\")\n"
      ],
      "metadata": {
        "id": "Kt51-dD8rVPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Show the first 5 records"
      ],
      "metadata": {
        "id": "gH-Bf8O4rb7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT * FROM unicorns LIMIT 5\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT3Ou6evrdnX",
        "outputId": "7372fc73-9bd7-44d7-8a57-1faae56552fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+----------+-------+-------+--------------------+--------------------+----+-----+----+----------+-----------------+\n",
            "|             Company|           Valuation|      Date|Country|   City|            Industry|           Investors|Year|month| day|ParsedDate|Valuation_numeric|\n",
            "+--------------------+--------------------+----------+-------+-------+--------------------+--------------------+----+-----+----+----------+-----------------+\n",
            "|           Bytedance|               140.0|  4/7/2017|  China|Beijing|Artificial intell...|0      Sequoia Ca...|2017| NULL|NULL|2017-04-07|            140.0|\n",
            "|1      Founders Fund| Draper Fisher Ju...| Rothen...|   NULL|   NULL|                NULL|                NULL|NULL| NULL|NULL|      NULL|             NULL|\n",
            "|2            Khos...|    LowercaseCapital|  capitalG|   NULL|   NULL|                NULL|                NULL|NULL| NULL|NULL|      NULL|             NULL|\n",
            "|3      Institutio...|   Sequoia Capita...|      NULL|   NULL|   NULL|                NULL|                NULL|NULL| NULL|NULL|      NULL|             NULL|\n",
            "|4      Sequoia Ca...|  Blackbird Ventures|    Mat...|   NULL|   NULL|                NULL|                NULL|NULL| NULL|NULL|      NULL|             NULL|\n",
            "+--------------------+--------------------+----------+-------+-------+--------------------+--------------------+----+-----+----+----------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Show the schema"
      ],
      "metadata": {
        "id": "VQzq4-xQrg87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AESk33xarhiC",
        "outputId": "7ccdea21-15f5-413f-f372-744a1282fae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Company: string (nullable = true)\n",
            " |-- Valuation: string (nullable = true)\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- Industry: string (nullable = true)\n",
            " |-- Investors: string (nullable = true)\n",
            " |-- Year: integer (nullable = true)\n",
            " |-- month: string (nullable = true)\n",
            " |-- day: string (nullable = true)\n",
            " |-- ParsedDate: date (nullable = true)\n",
            " |-- Valuation_numeric: float (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Count startups per country"
      ],
      "metadata": {
        "id": "34JcIj4ErixY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT Country, COUNT(*) AS num_startups\n",
        "FROM unicorns\n",
        "GROUP BY Country\n",
        "ORDER BY num_startups DESC\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R42PkuiUri61",
        "outputId": "347455e6-f3cc-419c-d427-d7dc3f0de6a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+------------+\n",
            "|           Country|num_startups|\n",
            "+------------------+------------+\n",
            "|              NULL|      870480|\n",
            "|       Alibaba ...|         936|\n",
            "|             Go...|         936|\n",
            "| McKesson Ventures|         936|\n",
            "|               ...|         936|\n",
            "|              2021|         480|\n",
            "|     United States|         477|\n",
            "|             China|         169|\n",
            "|              2020|         110|\n",
            "|              2019|         110|\n",
            "|              2018|         107|\n",
            "|             India|          51|\n",
            "|              2017|          46|\n",
            "|              2015|          37|\n",
            "|    United Kingdom|          37|\n",
            "|           Germany|          23|\n",
            "|              2016|          22|\n",
            "|            Israel|          21|\n",
            "|            France|          19|\n",
            "|            Brazil|          15|\n",
            "+------------------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Top 10 most valuable startups"
      ],
      "metadata": {
        "id": "3c6xv9wProkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT Company, Valuation_numeric\n",
        "FROM unicorns\n",
        "ORDER BY Valuation_numeric DESC\n",
        "LIMIT 10\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVg21_Mvrp6U",
        "outputId": "4328c7c5-fe16-4359-f641-48fa2a30d085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------------+\n",
            "|   Company|Valuation_numeric|\n",
            "+----------+-----------------+\n",
            "| Bytedance|            140.0|\n",
            "|    SpaceX|            100.3|\n",
            "|    Stripe|             95.0|\n",
            "|    Klarna|             45.6|\n",
            "|     Canva|             40.0|\n",
            "| Instacart|             39.0|\n",
            "|Databricks|             38.0|\n",
            "|   Revolut|             33.0|\n",
            "|    Nubank|             30.0|\n",
            "|Epic Games|             28.7|\n",
            "+----------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Filter startups in Fintech industry"
      ],
      "metadata": {
        "id": "aZlaA4Xerr9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT *\n",
        "FROM unicorns\n",
        "WHERE Industry = 'Fintech'\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZahzKi1rsQC",
        "outputId": "5543d8fa-2b8b-4234-a9f8-c16546704ff0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+----------+--------------+-------------+--------+--------------------+----+-----+----+----------+-----------------+\n",
            "|             Company|Valuation|      Date|       Country|         City|Industry|           Investors|Year|month| day|ParsedDate|Valuation_numeric|\n",
            "+--------------------+---------+----------+--------------+-------------+--------+--------------------+----+-----+----+----------+-----------------+\n",
            "|              Stripe|     95.0| 1/23/2014| United States|San Francisco| Fintech|0      Sequoia Ca...|2014| NULL|NULL|2014-01-23|             95.0|\n",
            "|              Klarna|     45.6|12/12/2011|        Sweden|    Stockholm| Fintech|0      Sequoia Ca...|2011| NULL|NULL|2011-12-12|             45.6|\n",
            "|             Revolut|     33.0| 4/26/2018|United Kingdom|       London| Fintech|0      Sequoia Ca...|2018| NULL|NULL|2018-04-26|             33.0|\n",
            "|              Nubank|     30.0|  3/1/2018|        Brazil|    Sao Paulo| Fintech|0      Sequoia Ca...|2018| NULL|NULL|2018-03-01|             30.0|\n",
            "|               Chime|     25.0|  3/5/2019| United States|San Francisco| Fintech|0      Sequoia Ca...|2019| NULL|NULL|2019-03-05|             25.0|\n",
            "|                 FTX|     25.0| 7/20/2021|     Hong Kong|         NULL| Fintech|0      Sequoia Ca...|2021| NULL|NULL|2021-07-20|             25.0|\n",
            "|        Checkout.com|     15.0|  5/2/2019|United Kingdom|       London| Fintech|0      Sequoia Ca...|2019| NULL|NULL|2019-05-02|             15.0|\n",
            "|  Plaid Technologies|     13.4|12/11/2018| United States|San Francisco| Fintech|0      Sequoia Ca...|2018| NULL|NULL|2018-12-11|             13.4|\n",
            "|                Brex|     12.3| 10/5/2018| United States|San Francisco| Fintech|0      Sequoia Ca...|2018| NULL|NULL|2018-10-05|             12.3|\n",
            "|              Ripple|     10.0|12/20/2019| United States|San Francisco| Fintech|0      Sequoia Ca...|2019| NULL|NULL|2019-12-20|             10.0|\n",
            "|               Gusto|     10.0|12/18/2015| United States|San Francisco| Fintech|0      Sequoia Ca...|2015| NULL|NULL|2015-12-18|             10.0|\n",
            "|                 N26|     9.23| 1/10/2019|       Germany|       Berlin| Fintech|0      Sequoia Ca...|2019| NULL|NULL|2019-01-10|             9.23|\n",
            "|               Rapyd|     8.75| 12/3/2019|United Kingdom|       London| Fintech|0      Sequoia Ca...|2019| NULL|NULL|2019-12-03|             8.75|\n",
            "|             Tipalti|      8.3| 10/6/2020| United States|    San Mateo| Fintech|0      Sequoia Ca...|2020| NULL|NULL|2020-10-06|              8.3|\n",
            "|          Fireblocks|      8.0| 7/27/2021| United States|     New York| Fintech|0      Sequoia Ca...|2021| NULL|NULL|2021-07-27|              8.0|\n",
            "|         Dapper Labs|      7.6| 3/30/2021|        Canada|    Vancouver| Fintech|0      Sequoia Ca...|2021| NULL|NULL|2021-03-30|              7.6|\n",
            "|                Toss|      7.4| 12/9/2018|   South Korea|        Seoul| Fintech|0      Sequoia Ca...|2018| NULL|NULL|2018-12-09|              7.4|\n",
            "|               Carta|      7.4|  5/6/2019| United States|San Francisco| Fintech|0      Sequoia Ca...|2019| NULL|NULL|2019-05-06|              7.4|\n",
            "|              Gemini|      7.1|11/19/2021| United States|     New York| Fintech|0      Sequoia Ca...|2021| NULL|NULL|2021-11-19|              7.1|\n",
            "|National Stock Ex...|      6.5|  7/1/2020|         India|       Mumbai| Fintech|0      Sequoia Ca...|2020| NULL|NULL|2020-07-01|              6.5|\n",
            "+--------------------+---------+----------+--------------+-------------+--------+--------------------+----+-----+----+----------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Count startups per city"
      ],
      "metadata": {
        "id": "PIvmcdS9rv3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT City, COUNT(*) AS count\n",
        "FROM unicorns\n",
        "GROUP BY City\n",
        "ORDER BY count DESC\n",
        "LIMIT 10\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8qQX_m_rxQS",
        "outputId": "104406f4-23c0-4ded-b4e3-fd799e2b7f1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+------+\n",
            "|         City| count|\n",
            "+-------------+------+\n",
            "|         NULL|874239|\n",
            "|San Francisco|   134|\n",
            "|     New York|    81|\n",
            "|      Beijing|    62|\n",
            "|           16|    46|\n",
            "|     Shanghai|    45|\n",
            "|            1|    43|\n",
            "|           22|    40|\n",
            "|           21|    40|\n",
            "|           13|    39|\n",
            "+-------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Count unicorns per year\n"
      ],
      "metadata": {
        "id": "fWUCiDPTrywn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT Year, COUNT(*) AS count\n",
        "FROM unicorns\n",
        "GROUP BY Year\n",
        "ORDER BY Year\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dz4rKlDdr1UI",
        "outputId": "9ab0f375-711c-462e-b423-f81838b13754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+\n",
            "|Year| count|\n",
            "+----+------+\n",
            "|NULL|875160|\n",
            "|2007|     1|\n",
            "|2010|     1|\n",
            "|2011|     2|\n",
            "|2012|     4|\n",
            "|2013|     3|\n",
            "|2014|    13|\n",
            "|2015|    37|\n",
            "|2016|    22|\n",
            "|2017|    46|\n",
            "|2018|   107|\n",
            "|2019|   110|\n",
            "|2020|   110|\n",
            "|2021|   480|\n",
            "+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Average valuation per industry"
      ],
      "metadata": {
        "id": "odZZY_sHr2tg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT Industry, AVG(Valuation_numeric) AS avg_valuation\n",
        "FROM unicorns\n",
        "GROUP BY Industry\n",
        "ORDER BY avg_valuation DESC\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hOsnfABr3F3",
        "outputId": "c026b8e7-eaee-4dcd-e7c8-a51d70c6ee99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+\n",
            "|            Industry|     avg_valuation|\n",
            "+--------------------+------------------+\n",
            "|            Finttech|              10.0|\n",
            "|               Other| 4.812941237991931|\n",
            "|Artificial intell...| 4.465797102969626|\n",
            "|             Fintech|3.8638421033558092|\n",
            "|Data management &...| 3.380555556880103|\n",
            "|              Edtech| 3.161851860858776|\n",
            "|            Hardware| 3.080937512218952|\n",
            "|Auto & transporta...| 3.079310339072655|\n",
            "|Internet software...| 2.896766457728997|\n",
            "|Supply chain, log...| 2.868431374138477|\n",
            "|E-commerce & dire...|2.8539215711986317|\n",
            "|   Consumer & retail|  2.78826089527296|\n",
            "|              Travel|2.7384615678053637|\n",
            "|              Health|2.6390476207884532|\n",
            "|       Cybersecurity| 2.622926857413315|\n",
            "|Mobile & telecomm...|2.1375675555822014|\n",
            "|Artificial Intell...| 1.175000011920929|\n",
            "|                   7|              NULL|\n",
            "|                  11|              NULL|\n",
            "|                   3|              NULL|\n",
            "+--------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Create Is_USA flag"
      ],
      "metadata": {
        "id": "rgw8gsItr7Ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT Company, Country,\n",
        "       CASE WHEN Country = 'United States' THEN TRUE ELSE FALSE END AS Is_USA\n",
        "FROM unicorns\n",
        "\"\"\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSEzmXVIr9_z",
        "outputId": "cd383eec-2729-4dc7-947c-8c0b9c2c6a76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------+------+\n",
            "|             Company|Country|Is_USA|\n",
            "+--------------------+-------+------+\n",
            "|           Bytedance|  China| false|\n",
            "|1      Founders Fund|   NULL| false|\n",
            "|2            Khos...|   NULL| false|\n",
            "|3      Institutio...|   NULL| false|\n",
            "|4      Sequoia Ca...|   NULL| false|\n",
            "+--------------------+-------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}